{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is a template pipeline for the RAG end-to-end system, this cell does not work for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "\n",
    "# Ensure NLTK's sentence tokenizer is downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Step 1: Read all `.txt` files from a directory\n",
    "def load_text_files(directory):\n",
    "    docs = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                docs.append(file.read())\n",
    "    return docs\n",
    "\n",
    "# Step 2: Chunk the documents with overlap\n",
    "def chunk_text(text, chunk_size=50, overlap_size=5):\n",
    "    sentences = nltk.sent_tokenize(text)  # Tokenize text into sentences\n",
    "    chunks = []\n",
    "    \n",
    "    # Split sentences into chunks with overlap\n",
    "    for i in range(0, len(sentences), chunk_size - overlap_size):\n",
    "        chunk = sentences[i:i + chunk_size]\n",
    "        chunks.append(' '.join(chunk))  # Join sentences back into a chunk of text\n",
    "        if i + chunk_size >= len(sentences):\n",
    "            break  # Avoid index overflow\n",
    "    return chunks\n",
    "\n",
    "# Step 3: Load documents from a directory and chunk them with overlap\n",
    "def process_directory(directory, chunk_size=50, overlap_size=5):\n",
    "    all_chunks = []\n",
    "    docs = load_text_files(directory)\n",
    "    for doc in docs:\n",
    "        all_chunks.extend(chunk_text(doc, chunk_size, overlap_size))  # Chunk each document with overlap\n",
    "    return all_chunks\n",
    "\n",
    "# Step 4: Embed the chunks and build the FAISS index\n",
    "def build_faiss_index(chunks):\n",
    "    embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    chunk_embeddings = embedder.encode(chunks)\n",
    "    dimension = chunk_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(np.array(chunk_embeddings))\n",
    "    return index, embedder\n",
    "\n",
    "# Step 5: Retrieve top-k relevant chunks based on query\n",
    "def retrieve_top_k_chunks(query, index, chunks, embedder, k=5):\n",
    "    query_embedding = embedder.encode([query])\n",
    "    distances, indices = index.search(np.array(query_embedding), k)\n",
    "    return [(chunks[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
    "\n",
    "# Step 6: Generate answer based on the top-k chunks\n",
    "def generate_answer(query, top_chunks, model):\n",
    "    context = \"\\n\".join([chunk for chunk, _ in top_chunks])\n",
    "    prompt = f\"Question: {query}\\n\\nContext:\\n{context}\\n\\nAnswer:\"\n",
    "    return model(prompt, max_length=10000, num_return_sequences=1)[0]['generated_text']\n",
    "\n",
    "# Step 7: Combine everything in a RAG pipeline\n",
    "def rag_pipeline(query, directory, k=5, chunk_size=50, overlap_size=5):\n",
    "    # Process the directory and chunk the documents with overlap\n",
    "    chunks = process_directory(directory, chunk_size, overlap_size)\n",
    "    \n",
    "    # Build the FAISS index\n",
    "    index, embedder = build_faiss_index(chunks)\n",
    "    \n",
    "    # Retrieve top-k relevant chunks\n",
    "    top_k_chunks = retrieve_top_k_chunks(query, index, chunks, embedder, k)\n",
    "    \n",
    "    # Load a pre-trained text generation model\n",
    "\n",
    "    model = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
    "    \n",
    "    # Generate the answer based on the top-k chunks\n",
    "    answer = generate_answer(query, top_k_chunks, model)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the directory containing .txt files\n",
    "    directory = \"/Users/alan/11711/nlp-from-scratch-assignment/data/crawled/crawled_text_data_test\"\n",
    "    \n",
    "    # Define the query\n",
    "    query = \"How many super bowls did the Steelers win?\"\n",
    "    \n",
    "    # Run the RAG pipeline with overlapping chunks\n",
    "    result = rag_pipeline(query, directory, k=5, chunk_size=50, overlap_size=5)\n",
    "    \n",
    "    # Print the result\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
